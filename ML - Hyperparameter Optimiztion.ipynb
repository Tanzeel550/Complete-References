{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read the data in\n",
    "df = pd.read_csv(\"data/diabetes.csv\")\n",
    "X = df.drop(labels='Outcome',axis=1)# independent variables\n",
    "y = df['Outcome'].values# dependent variables\n",
    "\n",
    "# Normalize Data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)\n",
    "\n",
    "#split our data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================\n",
    "# Hyperparameter Optimization\n",
    "Hyperparameters are a model’s inbuilt configuration variables. These variables require fine tuning to produce a better performing model. These parameters are model dependent and vary from model to model. For example a random forest model will have the following hyperparameters:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn = KNeighborsClassifier()\n",
    "kn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the above features are a model’s inbuilt features. It is very difficult to manually change the hyperparameters and fit them on my training data every time because <br>\n",
    "<ul>\n",
    "    <li>it is time-consuming</li>\n",
    "    <li>it is hard to keep track of hyperparameters we tried and we still have to try</li>\n",
    "</ul>\n",
    "In order to overcome this problem, GridSearchCV and RandomizedSearchCv are the best solutions <b>to choose the best parameters for classifying problems.</b>\n",
    "<br>\n",
    "<h2>1) What is GridSearchCV?</h2>\n",
    "    \n",
    "GridSearchCV is a library function that is a member of sklearn’s model_selection package. It is the most basic algorithms for Hyperparameter Optimization. It helps to loop through predefined hyperparameters and fit your estimator (model) on your training set. So, in the end, you can select the best parameters from the listed hyperparameters.\n",
    "<br>\n",
    "In addition to that, you can specify the number of times for the cross-validation for each set of hyperparameters.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    2.6s finished\n"
     ]
    }
   ],
   "source": [
    "kn = KNeighborsClassifier()\n",
    "params = {\n",
    "    'n_neighbors' : [5, 25],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "grid_kn = GridSearchCV(estimator = kn,\n",
    "                        param_grid = params,\n",
    "                        scoring = 'accuracy', \n",
    "                        cv = 5, \n",
    "                        verbose = 1,\n",
    "                        n_jobs = -1)\n",
    "grid_search = grid_kn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s break down the code block above. As usual, you need to import the GridSearchCV and the estimator/model (in my example KNClassifier) from the sklearn library.<br><br>\n",
    "\n",
    "The next step is to define the hyperparameters you want to try out. It is depending on the estimator you selected. All you need to do is create a dictionary (variable params in my code) that has the hyperparameters as keys and an iterable that holds the options you need to try out.<br><br>\n",
    "\n",
    "Then all you have to do is create an object of GridSearchCV. Here basically you need to define a few named arguments:<br>\n",
    "\n",
    "    estimator: estimator object you created\n",
    "    params_grid: the dictionary object that holds the hyperparameters you want to try\n",
    "    scoring: evaluation metric that you want to use, you can simply pass a valid string/ object of evaluation metric\n",
    "    cv: number of cross-validation you have to try for each selected set of hyperparameters\n",
    "    verbose: you can set it to 1 to get the detailed print out while you fit the data to GridSearchCV\n",
    "    n_jobs: number of processes you wish to run in parallel for this task if it -1 it will use all available processors.\n",
    "\n",
    "That is all pretty much you need to define. Then you have to fit your training data as you do normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score=nan,\n",
      "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                            metric='minkowski',\n",
      "                                            metric_params=None, n_jobs=None,\n",
      "                                            n_neighbors=5, p=2,\n",
      "                                            weights='uniform'),\n",
      "             iid='deprecated', n_jobs=-1,\n",
      "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
      "                         'n_neighbors': [5, 25],\n",
      "                         'weights': ['uniform', 'distance']},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring='accuracy', verbose=1)\n",
      "The best score for our search is  0.7568246716162192\n",
      "The best parameters searched by GridSearchCV are  {'algorithm': 'auto', 'n_neighbors': 25, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search)\n",
    "print(\"The best score for our search is \",grid_search.best_score_)\n",
    "print(\"The best parameters searched by GridSearchCV are \",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7401574803149606"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can use these parameters and use it to initialize to our algorithm and get the best result for our model.\n",
    "kn = KNeighborsClassifier(algorithm='auto',n_neighbors=25, weights='uniform')\n",
    "kn.fit(X_train,y_train)\n",
    "pred = kn.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
