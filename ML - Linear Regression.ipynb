{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Linear regression is one of the simplest supervised learningalgorithms in our toolkit. If you have ever taken an introductorystatistics course in college, likely the final topic you covered waslinear regression. In fact, it is so simple that it is sometimes notconsidered machine learning at all! Whatever you believe, the fact isthat linear regression—and its extensions—continues to be a commonand useful method of making predictions when the target vector is aquantitative value (e.g., home price, age).<br>\n",
    "\n",
    "\n",
    "# Best fitting line\n",
    "Linear regression assumes that the relationship between the featuresand the target vector is approximately linear. That is, the effect (alsocalled coefficient, weight, or parameter) of the features on the targetvector is constant. In our solution, for the sake of explanation wehave trained our model using only two features. This means ourlinear model will be:\n",
    "<img src=\"Images/linear_regression.png\">\n",
    "where ŷ is our target, x is the data for a single feature, ˆβ<sub>1</sub> and ˆβ<sub>2</sub> are the coefficients identified by fitting the model, and ε is the error.After we have fit our model, we can view the value of eachparameter. For example, ˆβ<sub>0</sub>, also called the bias or intercept, can beviewed using intercept_:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "x = load_boston()['data'][:,0:2]\n",
    "y = load_boston()['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create linear regression\n",
    "regression=LinearRegression()\n",
    "\n",
    "# Fit the linear regression\n",
    "\n",
    "model=regression.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.672855487846665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.31573497,  0.12981678])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see the bias or variance by intercept__\n",
    "print(model.intercept_)\n",
    "\n",
    "# we can see our B1, B2, B3, ... , Bn by using coef__\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.93951016, 29.45495725, 32.04688206, 26.85637359, 21.20041494,\n",
       "       19.91071653, 21.21082157, 21.39461405, 24.24056974, 21.55220053,\n",
       "       21.63144053, 21.47597579, 21.65110766, 26.83520356, 26.84618166,\n",
       "       24.10496473, 21.61227858, 21.64662423, 21.65068458, 21.2264536 ,\n",
       "       21.2865285 , 19.68749191, 21.62792324, 21.56516145, 27.48725537,\n",
       "       21.66203525, 23.24992577, 19.2252054 , 24.24983972, 15.73356501,\n",
       "       32.04346581, 21.5426527 , 32.70137766, 21.62253996, 20.13478101,\n",
       "       21.58811854, 17.35420103, 32.03329914, 21.42329541, 21.66044079,\n",
       "       21.57870648, 21.4787732 , 18.6431543 , 29.45731895, 21.60046693,\n",
       "       28.80474933, 20.46143093, 17.14720518, 24.25789412, 21.43597217,\n",
       "       20.96486403, 19.81884397, 21.50330581, 21.64700627, 21.63825409,\n",
       "       24.0986595 , 21.62714969, 20.32741091, 20.8407423 , 15.48157693,\n",
       "       21.29620262, 21.63131108, 21.19324776, 24.07610655, 21.65181491,\n",
       "       21.50093148, 21.64392154, 15.33135024, 21.64125673, 24.41233742,\n",
       "       18.53923329, 21.63202464, 19.87577099, 19.06259558, 21.62591833,\n",
       "       21.58143443, 21.50648526, 16.36478236, 24.87112948, 27.4859798 ,\n",
       "       23.26768902, 26.84591645, 26.20058347, 26.07545851, 21.65498489,\n",
       "       21.65367143, 21.65589421, 30.74247217, 21.65680668,  7.22921208,\n",
       "       21.66105331, 21.58321202, 21.66423277, 21.5770394 , 24.86406017,\n",
       "       23.22455962, 24.90418693, 21.62995658, 21.64618536, 21.6324351 ,\n",
       "       25.5348698 , 21.60062796, 24.37099273, 17.40342411, 21.16363182,\n",
       "       21.65502909, 21.62892412, 21.63946967, 21.51720446, 32.04461824,\n",
       "       14.20629182, 20.54609842, 21.64101677, 21.50849018, 21.65259477,\n",
       "       16.66075232, 21.5542086 , 23.25277054, 20.99243085, 20.14606538,\n",
       "       19.60834031, 26.21233513, 21.61813546, 20.62428387, 21.46071001,\n",
       "       21.64387733, 19.34680125])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.410477716659145\n",
      "92.53307570930329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "print(mean_absolute_error(y_test,pred))\n",
    "print(mean_squared_error(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b5a298b288>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major advantage of linear regression is its interpretability, inlarge part because the coefficients of the model are the effect of aone-unit change on the target vector. For example, the first feature inour solution is the number of crimes per resident. Our model’scoefficient of this feature was ~–1.25, meaning that if we multiplythis coefficient by 1,000 (since the target vector is the house price inthousands of dollars), we have the change in house price for eachadditional one crime per capita:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3157349676878392"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way we can see the effect of other features. For example, in the following figure \"ZN\" feature has 0.05757 effect and \"INDUS\" has -0.016418 effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.315735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.129817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index         0\n",
       "0  CRIM -0.315735\n",
       "1    ZN  0.129817"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect = pd.DataFrame(model.coef_,index=load_boston()['feature_names'][:2]).reset_index()\n",
    "effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.129817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index         0\n",
       "1    ZN  0.129817"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect[effect[0]==effect[0].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.315735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index         0\n",
       "0  CRIM -0.315735"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect[effect[0]==effect[0].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Interactive Effects\n",
    "Sometimes a feature’s effect on our target variable is at least partiallydependent on another feature. For example, imagine a simple coffee-based example where we have two binary features—the presence ofsugar (sugar) and whether or not we have stirred (stirred)—and we want to predict if the coffee tastes sweet. Just putting sugar in the coffee (sugar=1, stirred=0) won’t make the coffee taste sweet(all the sugar is at the bottom!) and just stirring the coffee without adding sugar (sugar=0, stirred=1) won’t make it sweet either.<br>\n",
    "Instead it is the interaction of putting sugar in the coffee and stirringthe coffee (sugar=1, stirred=1) that will make a coffee taste sweet. The effects of sugar and stir on sweetness are dependent on each other. In this case we say there is an interaction effect between the features sugar and stirred.<br>\n",
    "We can account for interaction effects by including a new feature comprising the product of corresponding values from the interacting features.<br>\n",
    "<img src=\"Images/linear_regression-2.png\">\n",
    "where x1 and x2 are the values of the sugar and stirred,respectively, and x1x2 represents the interaction between the two.<br>\n",
    "\n",
    "In our solution, we used a dataset containing only two features. To create an interaction term, we simply multiply those two values together for every observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11376"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_term = np.multiply(x[:,0],x[:,1])\n",
    "interaction_term[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, while often we will have a substantive reason for believingthere is an interaction between two features, sometimes we will not.In those cases it can be useful to use scikit-learn’s PolynomialFeatures to create interaction terms for allcombinations of features. We can then use model selection strategies to identify the combination of features and interaction terms thatproduce the best model.<br><br>\n",
    "To create interaction terms using PolynomialFeatures, there are three important parameters we must set. Most important,interaction_only=True tells PolynomialFeatures to only return interaction terms. By default, PolynomialFeatures will add a feature containing ones called a bias. We can prevent thatwith include_bias=False. Finally, the degree parameter determines the maximum number of features to create interaction terms from (in case we wanted to create an interaction term that is the combination of three features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "interaction = PolynomialFeatures(degree=3, include_bias=False, interaction_only=True)\n",
    "\n",
    "x = interaction.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the output of PolynomialFeatures from our solution by checking to see if the first observation’s feature values and interaction term value match our manually calculated version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][2]==interaction_term[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can perform our linear model on the features_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=10)\n",
    "\n",
    "regression=LinearRegression()\n",
    "\n",
    "model=regression.fit(x_train,y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,pred))\n",
    "print(mean_squared_error(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
