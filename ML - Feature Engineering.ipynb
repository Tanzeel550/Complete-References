{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# read the data in\n",
    "df = pd.read_csv(\"data/titanic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output or the prediction quality of any ML algorithm predominantly depends on the quality of input being passed. The process of creating appropriate data features by applying the business context is called feature engineering, and it is one of the most important aspects of building an efficient ML system. <br>\n",
    "\n",
    "<h2>1) Dealing with Missing Data</h2><br>\n",
    "Missing data can mislead or create problems for analyzing the data. In order to avoid any such issues, you need to impute missing data. Lets check whether our data contains Missing Values or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    False\n",
       "Survived       False\n",
       "Pclass         False\n",
       "Name           False\n",
       "Sex            False\n",
       "Age             True\n",
       "SibSp          False\n",
       "Parch          False\n",
       "Ticket         False\n",
       "Fare           False\n",
       "Cabin           True\n",
       "Embarked        True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e7f50dff88>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False, cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>i) Delete</h3> \n",
    "    You could simply delete the rows containing missing values. This technique is more suitable and effective when a number of missing values row count is insignificant (say < 5%) compare with the overall record count. You can achieve this using Panda’s dropna() function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    male      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female      1      0   \n",
       "2                             Heikkinen, Miss. Laina  female      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female      1      0   \n",
       "4                           Allen, Mr. William Henry    male      0      0   \n",
       "\n",
       "             Ticket     Fare  \n",
       "0         A/5 21171   7.2500  \n",
       "1          PC 17599  71.2833  \n",
       "2  STON/O2. 3101282   7.9250  \n",
       "3            113803  53.1000  \n",
       "4            373450   8.0500  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to drop the columns which contain Missing values, so axis=1\n",
    "df.dropna(axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(axis=1, labels='Cabin', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now we can see that 'Age' Column has been dropped temporarily and 'Cabin' Column permanently. <br>\n",
    "<h3>ii) Replace with the summary</h3>\n",
    "This is probably the most commonly used imputation technique. Summarization here is the mean, mode, or median for a respective column. For continuous or quantitative variables, either mean/average or mode or median value of the respective column can be used to replace the missing values. Whereas for categorical or qualitative variables, the mode (most frequent) summation technique works better. You can achieve this using Panda’s fillna() function.We can also use imputer method in Scikit-Learn.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.0\n",
       "1    38.0\n",
       "2    26.0\n",
       "3    35.0\n",
       "4    35.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are replacing NaN values in 'Age' column with 18\n",
    "df['Age'].fillna(18).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.0\n",
       "1    38.0\n",
       "2    26.0\n",
       "3    35.0\n",
       "4    35.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].fillna(df['Age'].mean()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0  22.0\n",
       "1  38.0\n",
       "2  26.0\n",
       "3  35.0\n",
       "4  35.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import impute\n",
    "\n",
    "# creating an object of imputer, there are many other options, you can see\n",
    "im = impute.SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "# im = impute.SimpleImputer(missing_values=np.nan,strategy='constant',fill_value=18)\n",
    "\n",
    "#fitting and trasnforming our 'Age' column to SimpleImputer\n",
    "dd = im.fit_transform(df['Age'].values[:,np.newaxis])\n",
    "\n",
    "pd.DataFrame(dd).head()\n",
    "#Now if we want to concat or replace 'Age' column with 'dd', we can also do so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>iii) Use a predictive model</h3>\n",
    "    This is an advanced technique. Here you can train a regression model for continuous variables and a classification model for categorical variables with the available data and use the model to predict the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================================================================================================================\n",
    "<h2>2) Handling Categorical Data</h2>\n",
    "Most of the ML libraries are designed to work well with numerical variables. So categorical variables in their original form of text description can’t be directly used for model building. Let’s learn some of the common methods of handling categorical data, based on their number of levels.\n",
    "\n",
    "<h3>i) Create a dummy variable</h3>\n",
    "This is a Boolean variable that indicates the presence of a category with the value 1 and 0 for absence. You should create k-1 dummy variables, where k is the number of levels. Scikit-learn provides a useful function, One Hot Encoder, to create a dummy variable for a given categorical variable (Listing 3-1).<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df[['Sex','Embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S\n",
       "0           0         1           0           0           1\n",
       "1           1         0           1           0           0\n",
       "2           1         0           0           0           1\n",
       "3           1         0           0           0           1\n",
       "4           0         1           0           0           1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_male  Embarked_Q  Embarked_S\n",
       "0         1           0           1\n",
       "1         0           0           0\n",
       "2         0           0           1\n",
       "3         0           0           1\n",
       "4         1           0           1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we use drop_first in our get_dummies it would be nicer for our model.\n",
    "df_dummies = pd.get_dummies(df[['Sex','Embarked']],drop_first=True)\n",
    "df_dummies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ii) Convert to number </h3>\n",
    "Another simple method is to represent the text description  of each level with a number by using the Label Encoder function of Scikit-learn. If the number of levels is high (example zip code, state, etc.), then you apply the business logic to combine levels to groups. For example, zip code or state can be combined with regions; however, in this method there is a risk of losing critical information. Another method is to combine categories based on similar frequency  (a new category can be high, medium, low)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas package's factorize function\n",
    "Embarked_pd_factorized = pd.factorize(df['Embarked'])[0]\n",
    "pd.DataFrame(Embarked_pd_factorized).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "Sex_label_encoded = le.fit_transform(df['Sex'].values)\n",
    "\n",
    "pd.DataFrame(Sex_label_encoded).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3) Handling Text Data</h2>\n",
    "As you know machines, as advanced as they may be, are not capable of understanding words and sentences in the same manner as humans do. In order to make documents’ corpora more palatable for computers, they must first be converted into some numerical structure. There are a few techniques used to achieve that, but in this post, I’m going to focus on Vector Space models a.k.a. Bag-of-Words (BoW) models.<br>\n",
    "\n",
    "Bag-of-Words is a very intuitive approach to this problem, the methods comprise of:<br>\n",
    "<ol>\n",
    "    <li>Splitting the documents into tokens by following some sort of pattern.</li>\n",
    "    <li>Assigning a weight to each token proportional to the frequency with which it shows up in the document and/or corpora. </li>\n",
    "    <li>Creating a document-term matrix with each row representing a document and each column addressing a token. </li>\n",
    "</ol>\n",
    "The vectorizer objects provided by Scikit-Learn are quite reliable right out of the box, they allow us to perform all the above steps at once efficiently.<br>\n",
    "\n",
    "<h3> i) Count Vectorizer</h3>\n",
    "    The most straightforward one, it counts the number of times a token shows up in the document and uses this value as its weight.\n",
    "\n",
    "<b>Note:</b> If we want to convert our data from Capital letters to lower case letter, use apply() function and use lower() function of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is our sample\n",
    "sample = ['problem of evil','evil queen','horizon problem']\n",
    "\n",
    "#like always import our required modul\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "#create an instance of CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "\n",
    "# fit and transform our sample to bag of word\n",
    "x_count_vec = vec.fit_transform(sample)\n",
    "\n",
    "x_count_vec\n",
    "# x_count_vec.toarray()\n",
    "# vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   evil  horizon  of  problem  queen\n",
       "0     1        0   1        1      0\n",
       "1     1        0   0        0      1\n",
       "2     0        1   0        1      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_count_vec.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ii) TF-IDF </h3>\n",
    "There are some issues with this approach, however: the raw word counts lead to fea‐tures that put too much weight on words that appear very frequently, and this can besuboptimal  in  some  classification  algorithms.  One  approach  to  fix  this  is  known  as  term frequency–inverse document frequency (TF–IDF), which weights the word countsby a measure of how often they appear in the documents. The syntax for computingthese features is similar to the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680919</td>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.605349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605349</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       evil   horizon        of   problem     queen\n",
       "0  0.517856  0.000000  0.680919  0.517856  0.000000\n",
       "1  0.605349  0.000000  0.000000  0.000000  0.795961\n",
       "2  0.000000  0.795961  0.000000  0.605349  0.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "\n",
    "x_tfid_vec = vec.fit_transform(sample)\n",
    "\n",
    "pd.DataFrame(x_tfid_vec.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================\n",
    "<h2>4) Feature Scaling</h2>\n",
    "The unit or scale of measurement varies for different variables, so an analysis with the raw measurement could be artificially skewed toward the variables with higher absolute values. Bringing all the different types of variable units in the same order of magnitude thus eliminates the potential outlier measurements that would misrepresent the finding and negatively affect the accuracy of the conclusion. Two broadly used methods for rescaling data are normalization and standardization.\n",
    "\n",
    "<h3> i) Standardization (StandardScaler) </h3>\n",
    "The standardization technique will transform the variables to have zero mean and standard deviation of one. The formula for standardization is given as follows, and the outcome is commonly known as z-scores.<br>\n",
    "Z = (X-u)/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.730108</td>\n",
       "      <td>-0.789272</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.502445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.726220</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.786845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.722332</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.488854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.718444</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.420730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.714556</td>\n",
       "      <td>-0.789272</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.486337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived    Pclass      Fare\n",
       "0    -1.730108 -0.789272  0.827377 -0.502445\n",
       "1    -1.726220  1.266990 -1.566107  0.786845\n",
       "2    -1.722332  1.266990  0.827377 -0.488854\n",
       "3    -1.718444  1.266990 -1.566107  0.420730\n",
       "4    -1.714556 -0.789272  0.827377 -0.486337"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#create an instance of StandardScaler()\n",
    "sc = StandardScaler()\n",
    "\n",
    "# fit and transform our numerical data to StandardScalar\n",
    "standardized_df = sc.fit_transform(df[['PassengerId', 'Survived', 'Pclass','Fare']])\n",
    "\n",
    "# convert our standardized data to dataframe\n",
    "standardized_df = pd.DataFrame(standardized_df, columns=['PassengerId', 'Survived', 'Pclass','Fare'])\n",
    "\n",
    "# print standardized data-frame \n",
    "standardized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ii) Normalization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.126428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.379284</td>\n",
       "      <td>0.916602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028041</td>\n",
       "      <td>0.014020</td>\n",
       "      <td>0.014020</td>\n",
       "      <td>0.999410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.331688</td>\n",
       "      <td>0.110563</td>\n",
       "      <td>0.331688</td>\n",
       "      <td>0.876209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075090</td>\n",
       "      <td>0.018773</td>\n",
       "      <td>0.018773</td>\n",
       "      <td>0.996823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.503021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301813</td>\n",
       "      <td>0.809864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived    Pclass      Fare\n",
       "0     0.126428  0.000000  0.379284  0.916602\n",
       "1     0.028041  0.014020  0.014020  0.999410\n",
       "2     0.331688  0.110563  0.331688  0.876209\n",
       "3     0.075090  0.018773  0.018773  0.996823\n",
       "4     0.503021  0.000000  0.301813  0.809864"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#create an instance of Normalizer\n",
    "nor = Normalizer()\n",
    "\n",
    "#fit and transform our data to Normalizer\n",
    "normalized_df = nor.fit_transform(df[['PassengerId', 'Survived', 'Pclass','Fare']])\n",
    "\n",
    "#convert our normalized data to dataFrame\n",
    "normalized_df = pd.DataFrame(normalized_df, columns=['PassengerId', 'Survived', 'Pclass','Fare'])\n",
    "\n",
    "#print our data-frame\n",
    "normalized_df.head()\n",
    "\n",
    "# from sklearn.preprocessing import normalize\n",
    "# normalized_df2 = normalize(df[['PassengerId', 'Survived', 'Pclass','Fare']])\n",
    "# normalized_df2 = pd.DataFrame(normalized_df2, columns=['PassengerId', 'Survived', 'Pclass','Fare'])\n",
    "# normalized_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
