{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read the data in\n",
    "df = pd.read_csv(\"data/diabetes.csv\")\n",
    "X = df.drop(labels='Outcome',axis=1)# independent variables\n",
    "y = df['Outcome'].values# dependent variables\n",
    "\n",
    "# Normalize Data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================================================\n",
    "In machine learning, we couldn’t fit the model on the training data and can’t say that the model will work accurately for the real data. For this, we must assure that our model got the correct patterns from the data, and it is not getting up too much noise. For this purpose, we use the cross-validation technique.<br>\n",
    "\n",
    "<h1>Cross-validation:</h1>\n",
    "It is a technique in which we train our model using the subset of the data-set and then evaluate using the complementary subset of the data-set.<br>\n",
    "\n",
    "The three steps involved in cross-validation are as follows :<br>\n",
    "    Reserve some portion of sample data-set.<br>\n",
    "    Using the rest data-set train the model.<br>\n",
    "    Test the model using the reserve portion of the data-set.<br>\n",
    "\n",
    "<h2>Methods of Cross Validation</h2>\n",
    "\n",
    "<h3>1) Train Test Split</h3>\n",
    "In this method, we perform training on the 70% of the given data-set and rest 30% is used for the testing purpose. The major drawback of this method is that we perform training on the 70% of the dataset, it may possible that the remaining 30% of the data contains some important information which we are leaving while training our model i.e higher bias. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Test Split predictions(first ten):  [0 1 1 1 1 0 0 0 0 0]\n",
      "Train Test Split Accuracy Score  0.696969696969697\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2017)\n",
    "\n",
    "# build a decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier(random_state=2017)\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print (\"Train Test Split predictions(first ten): \", pred[:10])\n",
    "print (\"Train Test Split Accuracy Score \", accuracy_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2) LOOCV (Leave One Out Cross Validation)</h3>\n",
    "In this method, we perform training on the whole data-set but leaves only one data-point of the available data-set and then iterates for each data-point. It has some advantages as well as disadvantages also.\n",
    "An advantage of using this method is that we make use of all data points and hence it is low bias.\n",
    "The major drawback of this method is that it leads to higher variation in the testing model as we are testing against one data point. If the data point is an outlier it can lead to higher variation. Another drawback is it takes a lot of execution time as it iterates over ‘the number of data points’ times.<br>\n",
    "\n",
    "<h3>3) K-Fold Cross Validation</h3>\n",
    "In this method, we split the data-set into k number of subsets(known as folds) then we perform training on the all the subsets but leave one(k-1) subset for the evaluation of the trained model. In this method, we iterate k times with a different subset reserved for testing purpose each time.<br>\n",
    "\n",
    "<i>It is always suggested that the value of k should be 10 as the lower value of k is takes towards validation and higher value of k leads to LOOCV method.</i>\n",
    "\n",
    "<b>Example</b><br>\n",
    "The diagram below shows an example of the training subsets and evaluation subsets generated in k-fold cross-validation. Here, we have total 25 instances. In first iteration we use the first 20 percent of data for evaluation, and the remaining 80 percent for training([1-5] testing and [5-25] training) while in the second iteration we use the second subset of 20 percent for evaluation, and the remaining three subsets of the data for training([5-10] testing and [1-5 and 10-25] training), and so on.\n",
    "<br>\n",
    "<img src=\"Images/K-Fold.png\">\n",
    "<img src=\"Images/K-Fold(2).png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparison of train/test split to cross-validation</h3>\n",
    "\n",
    "<b>Advantages of train/test split:</b>\n",
    "<ol>\n",
    "    <li>This runs K times faster than Leave One Out cross-validation because K-fold cross-validation repeats the train/test split K-times.</li>\n",
    "    <li>Simpler to examine the detailed results of the testing process.<li>\n",
    "</ol>\n",
    "\n",
    "<b>Advantages of cross-validation:</b>\n",
    "<ol>\n",
    "    <li>More accurate estimate of out-of-sample accuracy.</li>\n",
    "    <li>More “efficient” use of data as every observation is used for both training and testing.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold AUC Scores:  [0.62337662 0.74025974 0.7012987  0.57142857 0.66233766 0.72727273\n",
      " 0.83116883 0.77922078 0.63157895 0.73684211]\n",
      "CV AUC Score:  0.7004784688995216\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=10)\n",
    "print (\"Fold AUC Scores: \", scores)\n",
    "print (\"CV AUC Score: \", scores.mean())\n",
    "\n",
    "# evaluate the model using 10-fold cross-validation\n",
    "# train_scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=10)\n",
    "# test_scores = cross_val_score(clf, X_test, y_test, scoring='accuracy', cv=10)\n",
    "\n",
    "# print (\"Train Fold AUC Scores: \", train_scores)\n",
    "# print (\"Train CV AUC Score: \", train_scores.mean())\n",
    "\n",
    "# print (\"\\nTest Fold AUC Scores: \", test_scores)\n",
    "# print (\"Test CV AUC Score: \", test_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4) Stratified cross-validation</h2>\n",
    "Stratification is a technique where we rearrange the data in a way that each fold has a good representation of the whole dataset. It forces each fold to have at least m instances of each class. This approach ensures that one class of data is not overrepresented especially when the target variable is unbalanced.<br>\n",
    "\n",
    "For example in a binary classification problem where we want to predict if a passenger on Titanic survived or not. we have two classes here Passenger either survived or did not survive. We ensure that each fold has a percentage of passengers that survived and a percentage of passengers that did not survive.<br>\n",
    "\n",
    "<img src=\"Images/StratifiedKFold.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist.: [277 152], Train Acc: 1.000, Test Acc: 0.704\n",
      "\n",
      "Train CV accuracy: 1.000\n",
      "Test CV accuracy: 0.704\n",
      "Fold: 2, Class dist.: [277 152], Train Acc: 1.000, Test Acc: 0.639\n",
      "\n",
      "Train CV accuracy: 1.000\n",
      "Test CV accuracy: 0.671\n",
      "Fold: 3, Class dist.: [278 152], Train Acc: 1.000, Test Acc: 0.645\n",
      "\n",
      "Train CV accuracy: 1.000\n",
      "Test CV accuracy: 0.662\n",
      "Fold: 4, Class dist.: [278 152], Train Acc: 1.000, Test Acc: 0.664\n",
      "\n",
      "Train CV accuracy: 1.000\n",
      "Test CV accuracy: 0.663\n",
      "Fold: 5, Class dist.: [278 152], Train Acc: 1.000, Test Acc: 0.701\n",
      "\n",
      "Train CV accuracy: 1.000\n",
      "Test CV accuracy: 0.670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "kfold = model_selection.StratifiedKFold(n_splits=5, random_state=2019)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "k = 0\n",
    "\n",
    "for (train, test) in kfold.split(X_train, y_train):\n",
    "    clf.fit(X_train[train], y_train[train])    \n",
    "    train_score = clf.score(X_train[train], y_train[train])\n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "    # score for test set    \n",
    "    test_score = clf.score(X_train[test], y_train[test])\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    k += 1\n",
    "    \n",
    "    print('Fold: %s, Class dist.: %s, Train Acc: %.3f, Test Acc: %.3f'% (k, np.bincount(y_train[train]), train_score, test_score))\n",
    "    \n",
    "    print('\\nTrain CV accuracy: %.3f' % (np.mean(train_scores)))\n",
    "    print('Test CV accuracy: %.3f' % (np.mean(test_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
