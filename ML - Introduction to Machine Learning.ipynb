{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is machine learning?\n",
    "Machine learning is the practice  of programming computers to learn from data.In the above example, the program will  easily be able to determine if  given areimportant or are  “spam”. In machine learning, data referred to as  called trainingsets or examples.\n",
    "\n",
    "## Types of Systems of Machine Learning\n",
    "<ul>\n",
    "<li>Supervised Machine learning<br>\n",
    "<li>Unsupervised Machine Learning<br>\n",
    "<li>Reinforcement Machine Learning<br>\n",
    "</ul>\n",
    "\n",
    "# 1) Supervised Machine Learning\n",
    "In this type of machine-learning system, the data that you feed into thealgorithm, with the desired solution, are referred to as “labels.” \n",
    "<img src=\"Images/ML.png\">\n",
    "Supervised learning groups together a tasks of classification. The above program is a good example of this because it's been trained with many emails at the same time as their class.\n",
    "Another example is to predict a numeric value like the price of a flat, given a setof features (location, number of rooms, facilities) called predictors; this type oftask is called regression.\n",
    "\n",
    "## Types of Supervised Algorithms\n",
    "Broadly there are two types of commonly used supervised learning algorithms:•\n",
    "### i) Regression: \n",
    "The output to be predicted is a continuous number in relevance with a given input dataset. Example use cases are a prediction of retail sales, prediction of the number of staff required for each shift, number of car park spaces required for a retail store, a credit score for a customer, etc.\n",
    "### ii) Classification: \n",
    "The output to be predicted is the actual or the probability of an event/class and the number of classes to be predicted can be two or more. The algorithm should learn the patterns in the relevant input of each class from historical data and be able to predict the unseen class or event in the future, considering their input. An example use case is spam e-mail filtering where the output expected is to classify an e-mail into either spam or not spam.\n",
    "\n",
    "### The most important supervised algorithms\n",
    "-K-nears neighbors<br>\n",
    "-Linear regression<br>\n",
    "-Neural networks<br>\n",
    "-Support vector machines<br>\n",
    "-Logistic regression<br>\n",
    "-Decision trees and random forests<br>\n",
    "<br><br><br><br>\n",
    "\n",
    "# 2) Unsupervised Machine Learning\n",
    "In this type of machine-learning system, you can guess that the data is unlabeled. The objective of such cases would be to study the patterns in the input dataset to get a better understanding and identify similar patterns that can be grouped into specific classes or events.\n",
    "<img src=\"Images/ML.png\">\n",
    "## Types of Unsupervised Algorithms\n",
    "Following are some types of unsupervised learning:\n",
    "### i) Clustering: \n",
    "Assume that the classes are not known beforehand for a given dataset. The goal here is to divide the input dataset into logical groups of related items. Some examples are grouping similar news articles or grouping similar customers based on their profile.\n",
    "\n",
    "### ii) Dimension reduction: \n",
    "Here the goal is to simplify a large input dataset by mapping them to a lower dimensional space. For example, carrying analysis on a large dimension data set is very computationally intensive; so to simplify, you may want to find the key variables that hold a significant percentage (say 95%) of information and only use them for analysis.\n",
    "\n",
    "### The most important unsupervised algorithms\n",
    "-Clustering: k-means, hierarchical cluster analysis<br>\n",
    "-Association rule learning: Eclat, apriori-Visualization<br> \n",
    "-Dimensionality reduction: kernel PCA, t-distributed,PCA<br>\n",
    "\n",
    "======================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting the Data\n",
    "If you're in a foreign country and someone steals something of yours, you mightsay that everyone is a thief. This is an overgeneralization, and, in machinelearning, is called “overfitting”. This means that machines do the same thing:they can perform well when they're working with the training data, but they can'tgeneralize them properly.  For example, in the following figure you'll find a highdegree of life satisfaction model that overfits the data, but it works well with thetraining data.<br>\n",
    "<b>When does this occur?</b><br>\n",
    "Overfitting occurs when the model is very complex for the amount of training data given.<br>\n",
    "<b>Solutions</b><br>\n",
    "To solve the overfitting problem, you should do the following:\n",
    "-Gather more data for “training data”<br>\n",
    "-Reduce the noise level<br>\n",
    "-Select one with fewer parameter<br>\n",
    "\n",
    "# Underfitting the data\n",
    "From its name, underfitting is the opposite of overfitting, and you'll encounterthis when the model is very simple to learn. For example, using the example ofquality of life, real life is more complex than your model, so the predictionswon't yield the same, even in the training examples.\n",
    "<b>SolutionsTo fix this problem:</b>\n",
    "<ul>\n",
    "    <li>-Select the most powerful model, which has many parameters. </li>\n",
    "    <li>-Feed the best features into your algorithm. Here, I'm referring to feature engineering.</li>\n",
    "    <li>-Reduce the constraints on your model.</li>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Bias-Variance(2).png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to avoid Overfitting and Underfitting?\n",
    "\n",
    "The commonly used methodologies are:<br>\n",
    "\n",
    "-->Cross- Validation: A standard way to find out-of-sample prediction error is to use 5-fold cross validation.<br>\n",
    "-->Early Stopping: Its rules provide us the guidance as to how many iterations can be run before learner begins to over-fit.<br>\n",
    "-->Pruning: Pruning is extensively used while building related models. It simply removes the nodes which add little predictive power for the problem in hand.<br>\n",
    "-->Regularization: It introduces a cost term for bringing in more features with the objective function. Hence it tries to push the coefficients for many variables to zero and hence reduce cost term.<br>\n",
    "\n",
    "\n",
    "\n",
    "### Good Fit in a Statistical Model:\n",
    "\n",
    "Ideally, the case when the model makes the predictions with 0 error, is said to have a good fit on the data. This situation is achievable at a spot between overfitting and underfitting. In order to understand it we will have to look at the performance of our model with the passage of time, while it is learning from training dataset.<br>\n",
    "\n",
    "With the passage of time, our model will keep on learning and thus the error for the model on the training and testing data will keep on decreasing. If it will learn for too long, the model will become more prone to overfitting due to presence of noise and less useful details. Hence the performance of our model will decrease. In order to get a good fit, we will stop at a point just before where the error starts increasing. At this point the model is said to have good skills on training dataset as well our unseen testing dataset. <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Bias-Variance.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
